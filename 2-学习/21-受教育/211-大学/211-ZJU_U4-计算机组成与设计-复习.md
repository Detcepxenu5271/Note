# ZJU 计算机组成与设计 复习


## Ch1 Preface
CPU time：处理一项任务（job）的 CPU 时间，不包括 IO 等

Clock period：一个 clock cycle 的时间
Clock frequency (rate)：每秒的 clock cycle 数

$$
\begin{align}
CPU\ Time &= CPU\ Clock\ Cycles\times Clock\ Cycle\ Time \\
&= \frac{CPU\ Clock\ Cycles}{Clock\ Rate}
\end{align}
$$
$$
\begin{align}
Clock\ Cycles &= Instruction\ Count\times Cycles\ per\ Instruction \\
&= Instruction\ Count\times CPI\times Clock\ Cycle\ Time \\
&= \frac{Instruction\ Count\times CPI}{Clock\ Rate}
\end{align}
$$

## Ch4 Risc-v Part 1
P18
* sra 指令的 Func7 是否应该为 0100000？

指令执行过程（硬件）
1. Fetch
	- 从 instruction memory 获取指令
	- 修改 PC
2. Instruction decoding & Read Operand
3. Executive Control
	- 控制 ALU 的操作
4. Memory access
5. Write results to register
	- R-type：ALU 结果被写入寄存器
	- I-type：memory 读取到的数据被写入寄存器
6. Modify PC
	- branch instructions

R-Format Instructions
* 读入两个寄存器操作数
* ALU
* 写寄存器

Load/Store Instructions
* 读寄存器操作数
* 计算地址
* Load：读内存到寄存器
* Store：寄存器写到内存

Branch Instructions
* 读寄存器操作数
* 比较操作数（ALU）
* 计算目标地址

P36-41 Full datapath

## Ch4 Risc-v Part 2
RISC-V 适合流水线：
* 指令长度固定
* 指令格式少，规则
* Load/Store 的寻址（第三步算出地址，第四步 access memory）

Hazards（可能阻碍流水线的情况）
* Structure Hazards
	- 资源冲突
	- 假如 instructions 和 data 都放在一块内存，那么 Load/Store 就需要等待。所以要分开 instruction/data memories
* Data Hazards
	- 一条指令需要上条指令的数据
	- Forwarding (Bypassing)：添加新的 datapath，让结果直接参与下条指令（而不是等到存入寄存器或内存，再从寄存器或内存中读取）
* Control Hazards
	- Branch：等到跳转结果确定再 fetch 下一条指令
		+ 【？】Beq 的 ID 结束就可以判断了
	- Branch Prediction：预测跳转结果，直接 fetch 下一条指令，错了再停下来（stall）
	- 先执行 beq，再执行上条语句

Pileline registers
* stages 之间需要寄存器

2-bit Prediction
* Branch Hazard，预测策略的修改有一层缓冲
![](../../../img/2022-06-13_15-09-19_2BitPredictionOnBranchHazards.png)

Pipline 的 Exception 类似 Branch Prediction

## Ch5 Large and Fast: Exploiting Memory Hierarchy
### 5.1 Memory Technologies
Memories
* SRAM
	- 快，贵（需要的晶体管多）
* DRAM
	- 需要刷新

* Cache：SRAM and DRAM
* Virtual Memory：DRAM and DISK

### 5.2
### 5.3 The basics of Cache
Four Questions
1. Block placement
2. Block identification
3. Block replacement
4. Write strategy

Q1：Block placement
* Direct Mapped Cache（直接映射）
* Fully associative（全相联）
* Set associative（组相联）
	- n-way set：set have n blocks

Q2：Block Identification
* Tag
* Valid bit
* Index

Q3：Block Replacement
* 只对全相联和组相联有用

Q4：Write Strategy
* write-through cache：同时写回内存
	- Write misses：write-around
* write-back cache：暂时不写回内存
	- Write misses：write-allocate

### 5.4 Measuring and improving cache performance
$$
\begin{align}
Average\ Memory\ Assess\ time &= hit\ time + miss\ time \\
&= hit\ rate\times Cache\ time + miss\ rate\times memory\ time \\
&= 99\%\times 5 + (1-99\%)\times 45 = 5.5ns
\end{align}
$$

direct-mapped cache：miss rate 高

### 7.4 Virtual Memory
* write-back
* fully associative
